##########################
#
# dimension reduction
#
##########################

#
# PCA
#
from sklearn.decomposition import PCA
pca = PCA(n_components=2, whiten=False, random_state=1)

# fit & transform separately; useful to get variance explained, etc.
pca = pca.fit(X)
dat = pca.transform(X)
pca.explained_variance_ratio_

# fit & get transformed data in one step
dat = pca.fit_transform(X)

#
# t-SNE
#
from sklearn.manifold import TSNE

tsne = TSNE(n_components=2, perplexity=30.0, metric='euclidean', learning_rate='auto',
            init='random')
tsne_df = pd.DataFrame(tsne.fit_transform(dat), columns = ['TSNE1', 'TSNE2'])

##########################
# data
##########################
from sklearn.datasets.samples_generator import make_blobs
x, _ = make_blobs(n_samples=1000, centers=5, cluster_std=1)

##########################
# scale
##########################

# standardize
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit_transform(dat)

# min-max scaling
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaler.fit_transform(dat)

# for 1d ndarray
scaled = scaler.fit_transform(arr.reshape(-1, 1))
scaled.T[0]

##########################
#
# similarity metrics
#
##########################
sklearn.metrics.pairwise.cosine_similarity(X)

# jaccard index
from sklearn.metrics import pairwise_distances
1 - pairwise.pairwise_distances(df.to_numpy(), metric = "jaccard")

##########################
#
# clustering
#
##########################

#
# spectral clustering
#
from sklearn.cluster import SpectralClustering

num_clust = 5

sc = SpectralClustering(num_clust, eigen_solver='arpack', affinity='rbf', n_init=100, assign_labels='discretize')
sc.fit_predict(dat)  

# using pre-computered similarity scores
sc = SpectralClustering(.., affinity='precomputed')
sc.fit_predict(sim_mat)  
